{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_JwUsqQORslA","outputId":"93a8b235-5724-464f-fcbf-de7dcd4d45d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: albumentations==0.4.6 in /usr/local/lib/python3.7/dist-packages (0.4.6)\n","Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (0.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.21.6)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.17.2)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.3.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.2.0)\n"]}],"source":["import cv2\n","import imutils\n","import glob\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import torch\n","import torchvision\n","from torchvision.io import read_image\n","import torchvision.transforms as T\n","from torchvision.models.detection.rpn import AnchorGenerator\n","!pip install albumentations==0.4.6\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","import json\n","\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EMDnnZh656g5"},"outputs":[],"source":["def get_MobileNetmodel(trained=True, save_path=None):\n","  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","  model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n","\n","  num_classes = 2  # 1 class (bird) + background\n","\n","  # get number of input features for the classifier\n","  in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","  # replace the pre-trained head with a new one\n","  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","  if trained:\n","    if save_path == None: print(\"No path to the saved model\")\n","    else: model.load_state_dict(torch.load(save_path, map_location=torch.device('cpu')))\n","  model.to(device)\n","  return model\n","\n","def get_MobileNet320model(trained=True, save_path=None):\n","  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","  model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(pretrained=True)\n","\n","  num_classes = 2  # 1 class (bird) + background\n","\n","  # get number of input features for the classifier\n","  in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","  # replace the pre-trained head with a new one\n","  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","  model.to(device)\n","  if trained:\n","    if save_path == None: print(\"No path to the saved model\")\n","    else: model.load_state_dict(torch.load(save_path, map_location=torch.device('cpu')))\n","  \n","  return model\n","\n","def get_ResNet50model(trained=True, save_path=None):\n","  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","  \n","  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","  #model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=True)\n","  num_classes = 2  # 1 class (bird) + background\n","\n","  # get number of input features for the classifier\n","  in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","  # replace the pre-trained head with a new one\n","  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","  if trained:\n","      if save_path == None: print(\"No path to the saved model\")\n","      else: model.load_state_dict(torch.load(save_path, map_location=torch.device('cpu')))\n","\n","  model.to(device)\n","  return model\n","\n","def transforminput(maxsize):\n","    transforms = []\n","    # transforms.append(A.PadIfNeeded(maxsize, maxsize, border_mode=cv2.BORDER_CONSTANT))\n","    # transforms.append(A.Resize(576, 576))\n","    transforms.append(A.CenterCrop(width=576, height=576))\n","    return A.Compose(transforms)\n","\n","def transformback(size):\n","    transforms = []\n","    transforms.append(A.Resize(size[0], size[1]))        \n","    transforms.append(ToTensorV2(p=1.0)) \n","    return A.Compose(transforms, bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n","\n","toTensor = T.Compose([T.ToTensor()])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SaXlwNZLQIFP"},"outputs":[],"source":["###################\n","# Video Detection #\n","###################\n","# ROOT_DIR_SAVING = \"/content/drive/MyDrive/Thesis/savedmodel/\"\n","# MODEL_NAME = \"bestfasterrcnnv2_SGD0005_SchedulerReduceLR_Size576_Batch8_Epoch50_8020_rc.pth\"\n","# MODEL_NAME = \"bestMobileNetv3_SGD00005_SchedulerReduceLR_Size576_Batch8_Epoch100_8020_rc.pth\"\n","# MODEL_NAME = \"bestMobileNetv3320_SGD00005_SchedulerReduceLR_Size576_Batch8_Epoch100_8020_rc.pth\"\n","\n","ROOT_DIR_SAVING = \"/content/drive/MyDrive/Thesis/savedmodel/v1/\"\n","# MODEL_NAME = \"bestfasterrcnnv1_SGD0005_SchedulerReduceLR_Size576_Batch8_Epoch100.pth\"\n","MODEL_NAME = \"bestfasterrcnnv1_MobileNetv3_SGD00005_SchedulerReduceLR_Size576_Batch8_Epoch100.pth\"\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)\n","# model = get_ResNet50model(trained=True, save_path=ROOT_DIR_SAVING + MODEL_NAME)\n","model = get_MobileNetmodel(trained=True, save_path=ROOT_DIR_SAVING + MODEL_NAME)\n","# model = get_MobileNet320model(trained=True, save_path=ROOT_DIR_SAVING + MODEL_NAME)\n","model.eval()\n","\n","print(\"------------Load------------\")\n","\n","vid = cv2.VideoCapture(\"/content/drive/MyDrive/Thesis/videos/vid7.mp4\")\n","# cv2.namedWindow(\"img\", cv2.WINDOW_NORMAL)\n","iter = 0\n","all_frames = []\n","all_boxes = []\n","imgcount = 1\n","while vid.isOpened():\n","    # print(\"Enter\")\n","    ret, orig_frame = vid.read()\n","    # print(ret)\n","    if ret == True:\n","        orig_shape = orig_frame.shape\n","        size = (orig_shape[0], orig_shape[1])\n","        frame = cv2.cvtColor(orig_frame, cv2.COLOR_BGR2RGB).astype(np.float32)\n","        # frame = transforminput(max(orig_shape))(image=frame)['image']\n","        # frame = frame[0:0+1576, 0:0+1576]\n","\n","        frame /= 255.0\n","        # frame = cv2.resize(frame, (32*192,32*108))\n","        tensorframe = toTensor(frame)\n","        tensorframe = tensorframe[None, ...].cuda()\n","        outputs = model(tensorframe)\n","        outputs = [{k: v.to(device) for k, v in t.items()} for t in outputs]\n","\n","        score  = outputs[0]['scores']\n","        predboxes = outputs[0]['boxes']\n","        labels = outputs[0][\"labels\"].cpu().detach().numpy().astype(np.int32)\n","        print(\"Score\", score)\n","\n","        keepidx = torchvision.ops.nms(predboxes, score, 0.2).cpu().detach().numpy().astype(np.int32)\n","        score  = outputs[0]['scores'].cpu().detach().numpy()\n","        output = outputs[0]['boxes'].cpu().detach().numpy().astype(np.int32)\n","        score = score[keepidx]\n","        output = output[keepidx]\n","        labels = labels[keepidx]\n","\n","        confidenceidx = [idx for idx, elt in enumerate(score) if elt >= 0.1]\n","        output = output[confidenceidx]\n","        score = score[confidenceidx]\n","        labels = labels[confidenceidx]\n","        print(\"NMSScore\", score)\n","\n","        sample = {\n","            'image': frame,\n","            'bboxes': output,\n","            'labels': labels\n","        }\n","        print(size)\n","        sample = transformback(size)(**sample)\n","        boxes = sample['bboxes']\n","\n","        # loop over the boxes\n","        for idx, box in enumerate(boxes):\n","            cv2.rectangle(orig_frame,\n","                        (int(box[0]), int(box[1])),\n","                        (int(box[2]), int(box[3])),\n","                        (255, 0, 0), 5)\n","        #     cv2.putText(orig_frame, 'Bird '+ str(round(score[idx],3)), (int(box[0]), int(box[1])-15), cv2.FONT_HERSHEY_SIMPLEX, 1.6, (255,0,0), 3)\n","\n","        all_frames.append(orig_frame)\n","        all_boxes.append(boxes)\n","\n","        iter += 1\n","        imS = cv2.resize(orig_frame, (960, 540))\n","        cv2_imshow(imS)\n","        cv2.waitKey(1)\n","        if 0xFF == ord('q'):\n","            break\n","    else:\n","        break\n","\n","print(\"----------Prediction Done----------\")\n","# SAVE_PATH = \"/content/drive/MyDrive/Thesis/videos/prediction/predictionA10_Batch8_Epoch50_224.mp4\"\n","SAVE_PATH = \"/content/drive/MyDrive/Thesis/videos/prediction/predvid7Mobile.mp4\"\n","size = (size[1], size[0])\n","out = cv2.VideoWriter(SAVE_PATH,cv2.VideoWriter_fourcc(*'mp4v'), 20, size)\n"," \n","for i in range(len(all_frames)):\n","    out.write(all_frames[i])\n","out.release()\n","print(\"--------------Saved----------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5gQEuVvtsr1"},"outputs":[],"source":["###################\n","# Image Detection #\n","###################\n","import time\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)\n","ROOT_DIR_SAVING = \"/content/drive/MyDrive/Thesis/savedmodel/\"\n","# MODEL_NAME = \"bestfasterrcnnv2_SGD0005_SchedulerReduceLR_Size576_Batch8_Epoch50_8020_rc.pth\"\n","MODEL_NAME = \"bestMobileNetv3_SGD00005_SchedulerReduceLR_Size576_Batch8_Epoch100_8020_rc.pth\"\n","# MODEL_NAME = \"bestMobileNetv3320_SGD00005_SchedulerReduceLR_Size576_Batch8_Epoch100_8020_rc.pth\"\n","\n","# ROOT_DIR_SAVING = \"/content/drive/MyDrive/Thesis/savedmodel/v1/\"\n","# MODEL_NAME = \"bestfasterrcnnv1_SGD0005_SchedulerReduceLR_Size576_Batch8_Epoch100.pth\"\n","# MODEL_NAME = \"bestfasterrcnnv1_MobileNetv3_SGD00005_SchedulerReduceLR_Size576_Batch8_Epoch100.pth\"\n","# MODEL_NAME = \"bestfasterrcnnv1_MobileNetv3320_SGD00005_SchedulerReduceLR_Size576_Batch8_Epoch100.pth\"\n","# model = get_ResNet50model(trained=True, save_path=ROOT_DIR_SAVING + MODEL_NAME)\n","model = get_MobileNetmodel(trained=True, save_path=ROOT_DIR_SAVING + MODEL_NAME)\n","model.eval()\n","\n","def imagedetection(orig_frame):\n","  orig_frame = orig_frame[120:120+576, 600:600+576] #Pigeon\n","  # orig_frame = orig_frame[1000:1000+576, 1800:1800+576] #v3\n","  # orig_frame = orig_frame[700:700+576, 1850:1850+576] #v1\n","  # orig_frame = orig_frame[100:100+576, 530:530+576] #imgAU1\n","  orig_shape = orig_frame.shape\n","  print(orig_shape)\n","  frame = cv2.cvtColor(orig_frame, cv2.COLOR_BGR2RGB).astype(np.float32)\n","  frame /= 255.0\n","  # frame = cv2.resize(frame, (576, 576))\n","  tensorframe = toTensor(frame)\n","  tensorframe = tensorframe[None, ...].to(device)\n","  \n","  start = time.time()\n","  outputs = model(tensorframe)\n","  end = time.time()\n","  print(\"Time for one image\", end - start)\n","  outputs = [{k: v.to(device) for k, v in t.items()} for t in outputs]\n","\n","  score  = outputs[0]['scores']\n","  predboxes = outputs[0]['boxes']\n","\n","  keepidx = torchvision.ops.nms(predboxes, score, 0.2).cpu().detach().numpy().astype(np.int32)\n","  score  = outputs[0]['scores'].cpu().detach().numpy()\n","  output = outputs[0]['boxes'].cpu().detach().numpy().astype(np.int32)\n","  score = score[keepidx]\n","  output = output[keepidx]\n","\n","  confidenceidx = [idx for idx, elt in enumerate(score) if elt >= 0.1]\n","  output = output[confidenceidx]\n","  score = score[confidenceidx]\n","\n","  fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n","  sample = cv2.cvtColor(orig_frame, cv2.COLOR_BGR2RGB)\n","  print(\"Size\", sample.shape)\n","  for box in output:\n","      cv2.rectangle(sample,\n","                  (int(box[0]), int(box[1])),\n","                  (int(box[2]), int(box[3])),\n","                  (0, 0, 255), 2)\n","      # cv2.putText(sample, str(round(score[idx],3)), (int(box[0]), int(box[1])-6), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (1,0,0), 1)\n","      \n","  ax.imshow((sample).astype(np.uint8))\n","  ax.axis('off')\n","  # plt.savefig(\"/content/drive/MyDrive/Github/BirdDetection-FeaturesExtraction/images/imagerapport/imgpigeonv2.pdf\", bbox_inches='tight')\n","  plt.show()\n","\n","# orig_frame = cv2.imread('/content/drive/MyDrive/Github/BirdDetection-FeaturesExtraction/dataset/all_images/96.jpg', 1)\n","# orig_frame = cv2.imread('/content/drive/MyDrive/Thesis/videos/video2image/v5/v5img12.jpg', 1)\n","# orig_frame = cv2.imread('/content/drive/MyDrive/Github/BirdDetection-FeaturesExtraction/images/imgAU1.jpg', 1)\n","orig_frame = cv2.imread('/content/drive/MyDrive/Github/BirdDetection-FeaturesExtraction/images/ngbird1.JPG', 1)\n","# orig_frame = cv2.imread('/content/drive/MyDrive/Github/BirdDetection-FeaturesExtraction/images/flyingbirdimg1.jpg', 1)\n","# orig_frame = cv2.imread('/content/drive/MyDrive/Github/BirdDetection-FeaturesExtraction/images/COCO1.jpg', 1)\n","imagedetection(orig_frame)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"VideoDetection.ipynb","provenance":[],"mount_file_id":"1mQzrc_a17ZI6I-kDYMFqLY6ZO5tOd1PN","authorship_tag":"ABX9TyM7ILnvfpzKymtXLih0iDXb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}